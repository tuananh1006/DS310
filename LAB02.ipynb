{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpEBPdGxu+KH6zQk+yBp3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuananh1006/DS310/blob/main/Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name:** Nguyen Khanh Tuan Anh\n",
        "\n",
        "Lab02 :Use word embedding and tfidf for sentiment analysis\n"
      ],
      "metadata": {
        "id": "9jjBQh8fYvhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Use dataset UIT-VSFC to sentiment analysis for Vietnam Student Feedback"
      ],
      "metadata": {
        "id": "KyE-DK1GZT7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MiQAtwyTzOXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d04b04-3c08-423f-e093-f337583546c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='/content/drive/MyDrive/DS310/UIT-VSFC'\n",
        "import os\n",
        "os.listdir(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSR4T5KWT-n1",
        "outputId": "f6845dfd-f15c-4ec7-f6c6-7e63e8fbf300"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.txt', 'train', 'dev', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X_train=pd.read_csv(os.path.join(data_path,'train','sents.txt'),sep='\\t',header=None,index_col=None).iloc[:,0]\n",
        "X_dev=pd.read_csv(os.path.join(data_path,'dev','sents.txt'),sep='\\t',header=None,index_col=None).iloc[:,0]\n",
        "X_test=pd.read_csv(os.path.join(data_path,'test','sents.txt'),sep='\\t',header=None,index_col=None).iloc[:,0]\n",
        "y_train=pd.read_csv(os.path.join(data_path,'train','sentiments.txt'),sep='\\t',header=None,index_col=None).values.flatten()\n",
        "y_dev=pd.read_csv(os.path.join(data_path,'dev','sentiments.txt'),sep='\\t',header=None,index_col=None).values.flatten()\n",
        "y_test=pd.read_csv(os.path.join(data_path,'test','sentiments.txt'),sep='\\t',header=None,index_col=None).values.flatten()"
      ],
      "metadata": {
        "id": "_OeBWD7BUNN0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMXgDMSNUO5s",
        "outputId": "bdbac3fe-f47c-45a4-9c5e-87777199e176"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            slide giáo trình đầy đủ .\n",
              "1       nhiệt tình giảng dạy , gần gũi với sinh viên .\n",
              "2                 đi học đầy đủ full điểm chuyên cần .\n",
              "3    chưa áp dụng công nghệ thông tin và các thiết ...\n",
              "4    thầy giảng bài hay , có nhiều bài tập ví dụ ng...\n",
              "5    giảng viên đảm bảo thời gian lên lớp , tích cự...\n",
              "6    em sẽ nợ môn này , nhưng em sẽ học lại ở các h...\n",
              "7    thời lượng học quá dài , không đảm bảo tiếp th...\n",
              "8    nội dung môn học có phần thiếu trọng tâm , hầu...\n",
              "9    cần nói rõ hơn bằng cách trình bày lên bảng th...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbLw7jr2Vcmh",
        "outputId": "c08a9c60-b34b-48c4-ec5e-0f01499bfed8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 0, ..., 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import feature_extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_idf=TfidfVectorizer(ngram_range=(2,2),analyzer='word')\n",
        "tf_idf.fit(X_train)\n",
        "X_train_encoded=tf_idf.transform(X_train)\n",
        "X_dev_encoded=tf_idf.transform(X_dev)\n",
        "X_test_encoded=tf_idf.transform(X_test)"
      ],
      "metadata": {
        "id": "5PqgW_geVzbM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf=MultinomialNB()\n",
        "clf.fit(X_train_encoded,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ittwzgAZXrIC",
        "outputId": "05df3853-7cb5-4645-a74c-395e3a4fa976"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping={\n",
        "    0:'negative',\n",
        "    1:'neutral',\n",
        "    2:'positive'\n",
        "}"
      ],
      "metadata": {
        "id": "BBWjW17yX2_U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_dev.iloc[0])\n",
        "print(class_mapping[clf.predict(X_dev_encoded[0])[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoD5FVL6X65L",
        "outputId": "ac2bb7ab-7feb-45bd-cf23-f7cf62cf8f86"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "giáo trình chưa cụ thể .\n",
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_dev,clf.predict(X_dev_encoded)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCxCQSWHX-Jt",
        "outputId": "4709ec74-839a-43e8-af1b-0df034653a77"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88       705\n",
            "           1       0.00      0.00      0.00        73\n",
            "           2       0.89      0.92      0.90       805\n",
            "\n",
            "    accuracy                           0.87      1583\n",
            "   macro avg       0.58      0.61      0.59      1583\n",
            "weighted avg       0.83      0.87      0.85      1583\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,clf.predict(X_test_encoded)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jA4BsRSYZGf",
        "outputId": "b6c5635c-5726-4599-d7dc-67c8d2b33478"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88      1409\n",
            "           1       0.00      0.00      0.00       167\n",
            "           2       0.88      0.91      0.90      1590\n",
            "\n",
            "    accuracy                           0.86      3166\n",
            "   macro avg       0.58      0.61      0.59      3166\n",
            "weighted avg       0.82      0.86      0.84      3166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Word Embedding"
      ],
      "metadata": {
        "id": "SHXe3gBbZuPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWBhbbx5aF5p",
        "outputId": "3dbc0f13-6eb0-4252-f3ba-78c5d327d363"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n",
            "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi import ViTokenizer\n",
        "ViTokenizer.tokenize('Đại học Quốc Gia Hồ Chí Minh là đại học ở TPHCM').split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDo2Dk8SbNpZ",
        "outputId": "25f0f426-7858-4248-e6b1-baab7cf40ad0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Đại_học', 'Quốc_Gia', 'Hồ_Chí_Minh', 'là', 'đại_học', 'ở', 'TPHCM']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi import ViTokenizer\n",
        "V=[]\n",
        "for t in X_train:\n",
        "  V.extend(ViTokenizer.tokenize(t).split())\n",
        "V=list(set(V))"
      ],
      "metadata": {
        "id": "V_yJjMI1Z1OC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HocI6PQFb68s",
        "outputId": "036e7bad-a6e7-439b-c6ea-8c034dc401d9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3704"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Vocabulary by manual"
      ],
      "metadata": {
        "id": "DFMGfySgczfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index={ w:i+2 for i,w in enumerate(V)}\n",
        "word_to_index['PAD']=0\n",
        "word_to_index['UNK']=1\n",
        "index_to_word={i:w for w,i in word_to_index.items()}"
      ],
      "metadata": {
        "id": "omUQflxBcJFD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6O1_DaIdzIb",
        "outputId": "c748d195-891a-4898-dcd6-da7a0002c4d1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['slide giáo trình đầy đủ .',\n",
              "       'nhiệt tình giảng dạy , gần gũi với sinh viên .',\n",
              "       'đi học đầy đủ full điểm chuyên cần .', ...,\n",
              "       'giao bài tập quá nhiều .', 'giáo viên dạy dễ hiểu , nhiệt tình .',\n",
              "       'gói gọn doubledot hay , tận tình , phù hợp với mọi trình độ cũng như nhu cầu môn học .'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pyvi import ViTokenizer\n",
        "max_len = 100\n",
        "def encoding(X):\n",
        "  tokenized_sentence=[ViTokenizer.tokenize(s) for s in X]\n",
        "  X=[]\n",
        "  for s in tokenized_sentence:\n",
        "    X.append([word_to_index[w] if w in word_to_index else word_to_index['UNK'] for w in s.split()])\n",
        "  X=pad_sequences(X,maxlen=max_len,padding='post',value=word_to_index[\"PAD\"])\n",
        "  return X\n",
        "\n"
      ],
      "metadata": {
        "id": "lTuaMWD7d30_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding('Con mèo là gì').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srNSJSR9sGs0",
        "outputId": "0cbbb875-2a9a-4b79-8fb6-77256d86361d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build by Keras"
      ],
      "metadata": {
        "id": "SJaXNbZftRz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pyvi import ViTokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "max_len = 100\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X_train)\n",
        "word_to_index=word_tokenizer.word_index\n",
        "def encoding(X):\n",
        "  sentences = []\n",
        "  max_len=100\n",
        "  for t in X:\n",
        "    tokenized_sentence = ViTokenizer.tokenize(t)\n",
        "    sentences.append(tokenized_sentence)\n",
        "  X =word_tokenizer.texts_to_sequences(sentences)\n",
        "  X = pad_sequences(maxlen = max_len, sequences = X,padding = \"post\", value =0)\n",
        "  return X"
      ],
      "metadata": {
        "id": "w2hKsU5stXbN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Model"
      ],
      "metadata": {
        "id": "9Q_JOwTUxwHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = encoding(X_train)\n",
        "X_dev_encoded = encoding(X_dev)\n",
        "X_test_encoded = encoding(X_test)"
      ],
      "metadata": {
        "id": "1t8kTJ0iu3DE"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, Flatten,Input\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import Lion\n",
        "input = Input(shape = (max_len, ))\n",
        "emb = Embedding(input_dim=len(word_to_index)+1,output_dim=300,input_length=max_len)(input)\n",
        "flat = Flatten()(emb)\n",
        "output = Dense(3, activation=\"sigmoid\")(flat)\n",
        "model = Model(input, output)\n",
        "model.compile(optimizer=Lion(),\n",
        "loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9U59ysLvHgI",
        "outputId": "db1235a8-10f6-4632-d274-d8ad04fe8bbb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 100, 300)          746700    \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 836703 (3.19 MB)\n",
            "Trainable params: 836703 (3.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j07qgJ-JzHFN",
        "outputId": "84d2c691-4bf8-4035-97c4-e4c27ccdcb93"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2488"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "model.fit(X_train_encoded,to_categorical(y_train, num_classes=3),validation_data=(X_dev_encoded,\n",
        "to_categorical(y_dev, num_classes=3)),\n",
        " batch_size=128, epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmagzaoOzsBz",
        "outputId": "22fe6b58-111c-4686-81e5-dfecc06bf13e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 4s 39ms/step - loss: 0.5334 - binary_accuracy: 0.7198 - val_loss: 0.5277 - val_binary_accuracy: 0.7473\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 6s 62ms/step - loss: 0.4839 - binary_accuracy: 0.7706 - val_loss: 0.4375 - val_binary_accuracy: 0.7911\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 4s 42ms/step - loss: 0.3916 - binary_accuracy: 0.8407 - val_loss: 0.3701 - val_binary_accuracy: 0.8709\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 3s 38ms/step - loss: 0.3224 - binary_accuracy: 0.8885 - val_loss: 0.3138 - val_binary_accuracy: 0.8825\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 3s 39ms/step - loss: 0.2699 - binary_accuracy: 0.9012 - val_loss: 0.2772 - val_binary_accuracy: 0.8928\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 0.2308 - binary_accuracy: 0.9136 - val_loss: 0.2511 - val_binary_accuracy: 0.9071\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 4s 40ms/step - loss: 0.1997 - binary_accuracy: 0.9277 - val_loss: 0.2309 - val_binary_accuracy: 0.9151\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 3s 38ms/step - loss: 0.1752 - binary_accuracy: 0.9372 - val_loss: 0.2185 - val_binary_accuracy: 0.9210\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 3s 37ms/step - loss: 0.1547 - binary_accuracy: 0.9449 - val_loss: 0.2089 - val_binary_accuracy: 0.9238\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 5s 60ms/step - loss: 0.1365 - binary_accuracy: 0.9517 - val_loss: 0.2004 - val_binary_accuracy: 0.9267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a409c89f220>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_dev,model.predict(X_dev_encoded).argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paEfU8hS0NoY",
        "outputId": "b60c01ec-c540-40f4-dc60-f1f9d2b784dd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.90       705\n",
            "           1       0.80      0.05      0.10        73\n",
            "           2       0.90      0.94      0.92       805\n",
            "\n",
            "    accuracy                           0.89      1583\n",
            "   macro avg       0.86      0.64      0.64      1583\n",
            "weighted avg       0.88      0.89      0.87      1583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When i test different optimizer, i found when use Lion precision is higher than Adam(0.86>0.82).But recall quite low(0.64<0.74). I think it's has trade off between recall and precision when choose optimizer."
      ],
      "metadata": {
        "id": "_CdMy-TL3_rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,model.predict(X_test_encoded).argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5oYm1j2GVv",
        "outputId": "33141ac7-ce09-47ce-f493-21eda00a85f8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89      1409\n",
            "           1       0.62      0.03      0.06       167\n",
            "           2       0.90      0.92      0.91      1590\n",
            "\n",
            "    accuracy                           0.88      3166\n",
            "   macro avg       0.79      0.63      0.62      3166\n",
            "weighted avg       0.87      0.88      0.86      3166\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam is better than lion with default parameters when compare macro avg and accuracy"
      ],
      "metadata": {
        "id": "C_S2phEK4sUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Pretrain Embedding"
      ],
      "metadata": {
        "id": "xtfF9GQr52RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/W2V_ner.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nE6opPu7RK7",
        "outputId": "4ed825c5-f692-4235-b5ec-348427a14e3c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/W2V_ner.vec.zip\n",
            "  inflating: W2V_ner.vec             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = []\n",
        "embeddings_index = {}\n",
        "embedding_dim = 300\n",
        "max_feature = len(embeddings_index) + 1\n",
        "f = open('W2V_ner.vec')\n",
        "for line in f:\n",
        " values = line.split(' ')\n",
        " word = values[0]\n",
        " word_dict.append(word)\n",
        " try:\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        " except Exception as e:\n",
        "  pass\n",
        "f.close()\n",
        "print('Embedding data loaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAetDRL92cKg",
        "outputId": "cbc2dab9-8111-4daa-b6c9-ed81471ec95e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding data loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_words = len(word_to_index) + 1\n",
        "# first create a matrix of zeros, this is our embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "# for each word in out tokenizer lets try to find that work in our w2v model\n",
        "for word, i in word_to_index.items():\n",
        " if i > max_feature:\n",
        "  continue\n",
        " embedding_vector = embeddings_index.get(word)\n",
        " if embedding_vector is not None:\n",
        " # we found the word - add that words vector to the matrix\n",
        "  embedding_matrix[i] = embedding_vector\n",
        " else:\n",
        " # doesn't exist, assign a random vector\n",
        "  embedding_matrix[i] = np.random.randn(embedding_dim)"
      ],
      "metadata": {
        "id": "QAU0v0Rh6BxR"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, Flatten,Input\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "input = Input(shape = (max_len, ))\n",
        "emb = Embedding(input_dim=num_words,\n",
        " output_dim=embedding_dim,\n",
        "embeddings_initializer=Constant(embedding_matrix),\n",
        " input_length=max_len,\n",
        "trainable=True)(input)\n",
        "flat = Flatten()(emb)\n",
        "output = Dense(3, activation=\"sigmoid\")(flat)\n",
        "model = Model(input, output)\n",
        "model.compile(optimizer=\"adam\",\n",
        "loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPUS3IhaATkY",
        "outputId": "10311cbe-c3cb-4dcd-fafd-12999cd4bff5"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, 100, 300)          746700    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 836703 (3.19 MB)\n",
            "Trainable params: 836703 (3.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "model.fit(X_train_encoded,to_categorical(y_train, num_classes=3),validation_data=(X_dev_encoded,\n",
        "to_categorical(y_dev, num_classes=3)),\n",
        " batch_size=128, epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_X0BzCEBGDa",
        "outputId": "e8c192d1-0b6f-4f29-849f-82e1910e4d84"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 10s 97ms/step - loss: 0.4096 - binary_accuracy: 0.8138 - val_loss: 0.2631 - val_binary_accuracy: 0.9046\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 7s 79ms/step - loss: 0.2097 - binary_accuracy: 0.9262 - val_loss: 0.2037 - val_binary_accuracy: 0.9286\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 5s 53ms/step - loss: 0.1693 - binary_accuracy: 0.9433 - val_loss: 0.1877 - val_binary_accuracy: 0.9316\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 7s 76ms/step - loss: 0.1468 - binary_accuracy: 0.9497 - val_loss: 0.1817 - val_binary_accuracy: 0.9383\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 6s 69ms/step - loss: 0.1303 - binary_accuracy: 0.9559 - val_loss: 0.1799 - val_binary_accuracy: 0.9379\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 5s 53ms/step - loss: 0.1165 - binary_accuracy: 0.9613 - val_loss: 0.1814 - val_binary_accuracy: 0.9398\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 5s 51ms/step - loss: 0.1046 - binary_accuracy: 0.9667 - val_loss: 0.1816 - val_binary_accuracy: 0.9379\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 6s 71ms/step - loss: 0.0944 - binary_accuracy: 0.9702 - val_loss: 0.1868 - val_binary_accuracy: 0.9391\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 5s 54ms/step - loss: 0.0849 - binary_accuracy: 0.9731 - val_loss: 0.1923 - val_binary_accuracy: 0.9377\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 3s 35ms/step - loss: 0.0771 - binary_accuracy: 0.9763 - val_loss: 0.1970 - val_binary_accuracy: 0.9377\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a409d2d2d40>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_dev,model.predict(X_dev_encoded).argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8RhDbL9BLNw",
        "outputId": "fb622df2-4c31-4485-c54f-f6705c3e7e1c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 1s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       705\n",
            "           1       0.71      0.23      0.35        73\n",
            "           2       0.93      0.93      0.93       805\n",
            "\n",
            "    accuracy                           0.91      1583\n",
            "   macro avg       0.84      0.70      0.73      1583\n",
            "weighted avg       0.90      0.91      0.90      1583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,model.predict(X_test_encoded).argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsvimUYBB35g",
        "outputId": "3ef9f39c-3683-4f95-867b-e83e85803883"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      1409\n",
            "           1       0.60      0.16      0.25       167\n",
            "           2       0.92      0.91      0.92      1590\n",
            "\n",
            "    accuracy                           0.89      3166\n",
            "   macro avg       0.80      0.67      0.69      3166\n",
            "weighted avg       0.88      0.89      0.88      3166\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result show lower than use embedding by manual vocabulary. I think the reason that the word student use maybe different than vocabulary which have pretrained on WikiVocabulary."
      ],
      "metadata": {
        "id": "jrcHbHPiCKNg"
      }
    }
  ]
}
